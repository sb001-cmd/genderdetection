{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0bbac0-3985-4da6-a12e-4a3388356fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dataset Path\n",
    "DATASET_PATH = r\"C:\\Users\\user\\Autolighting\\UTKFace\"  # Folder where files will be extracted\n",
    "\n",
    "\n",
    "# Load images and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "for file in os.listdir(DATASET_PATH):\n",
    "    try:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            # Filename format: age_gender_race.jpg (e.g., 25_1_2.jpg -> Gender: 1 (Male), 0 (Female))\n",
    "            parts = file.split(\"_\")\n",
    "            gender = int(parts[1])  # Gender label (0 = Female, 1 = Male)\n",
    "\n",
    "            img_path = os.path.join(DATASET_PATH, file)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (64, 64))  # Resize image\n",
    "            img = img / 255.0  # Normalize pixel values\n",
    "\n",
    "            images.append(img)\n",
    "            labels.append(gender)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "images = np.array(images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c61d79-cfa7-4205-a882-dc86373371c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Sigmoid for binary classification (Male/Female)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"gender_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7211c-b836-405c-a31e-807d23aa6ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the pre-trained deep learning model\n",
    "MODEL_PATH = \"gender_model.h5\"  # Replace with your model's path\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# Define gender categories\n",
    "gender_classes = ['Male', 'Female']\n",
    "\n",
    "# Load OpenCV's pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Initialize Raspberry Pi Camera\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "def preprocess_face(face):\n",
    "    \"\"\"Preprocess face for gender classification.\"\"\"\n",
    "    face = cv2.resize(face, (64, 64))  # Resize to model input size\n",
    "    face = face / 255.0  # Normalize pixel values\n",
    "    face = np.expand_dims(face, axis=0)  # Add batch dimension\n",
    "    return face\n",
    "\n",
    "while True:\n",
    "    ret, frame = camera.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        processed_face = preprocess_face(face)\n",
    "        \n",
    "        # Predict gender\n",
    "        prediction = model.predict(processed_face)[0]\n",
    "        gender = gender_classes[np.argmax(prediction)]\n",
    "        \n",
    "        # Display result\n",
    "        label = f\"Gender: {gender}\"\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Gender Classification\", frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7901a-011e-4001-8a8e-9d9380474df1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
